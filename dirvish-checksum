#!/usr/bin/perl
use strict;
use warnings;
# version:  20150104
# finds files in directory and MD5sums and SHA1sums them, being smart enough to
# check against previous backup for hard links
#
#
#
#
# Copyright (C) 2008-2015  Glen Pitt-Pladdy
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
#
# See https://www.pitt-pladdy.com/blog/_20120412-224240_0100_dirvish-checksum_available_again/


use Cwd;

# default config file
my $CONFIG = "/etc/dirvish/master.conf";

my $GZIP = "/bin/gzip";
my $BZIP2 = "/bin/bzip2";

my @CHECKS = (
	'MD5SUMS',
	'SHA1SUMS',
#	'SHA256SUMS',
	'SHA512SUMS',
);

# chaches
my $inodespathprev='';
my %filestatsprev;
my %filesbyinodeprev;
my $inodespathnew='';
my %filestatsnew;
my %filesbyinodenew;


# arguments accepted:
#	--nosha1sums	disables SHA1SUMS
#	--nomd5sums		disables MD5SUMS
#	--no......		disables ........
#	--config=<path>		alternate config file to use
#	--debug		prints extra info for debugging
#
# By default we generate SHA1 and MD5 checksums

# get command line args
my %args;
foreach my $arg (@ARGV) {
	if ( $arg =~ /^--([^\-=]+)$/ ) {
		# true value
		$args{$1} = 1;
	} elsif ( $arg =~ /^--([^\-=]+)=([^=]+)$/ ) {
		# specified value
		$args{$1} = $2;
	}
}
# check for "stupid users"
if (  $args{'nosha512ums'} and $args{'nosha1sums'} and $args{'nomd5sums'} ) {
	die "This is completely pointless - I give up!\n";
}
# check for unknown args
foreach my $arg (keys %args) {
	if ( $arg =~ /^no(.+)$/ ) {
		my $sum = uc $1;
		my $found = 0;
		foreach (@CHECKS) {
			if ( $sum eq $_ ) {
				$found = 1;
				last;
			}
		}
		if ( ! $found ) { usage (); }
	}
}
# check for usual calls for help
if ( $args{help} or $args{h} or $args{'?'} ) { usage (); }
sub usage {
	die "Usage: $0 [--no(checksumtype)] ... [--confg=configfile] [--debug]\n";
}

# get relevant algorithms in
foreach my $alg (@CHECKS) {
	if ( exists ( $args{'no'.lc($alg)} ) ) { next; }
	if ( $alg =~ /^SHA\d+SUMS$/ ) {
		use Digest::SHA;
	} elsif ( $alg eq 'MD5SUMS' ) {
		use Digest::MD5;
	}
}


# read the master config
my %banks;
if ( -f $CONFIG ) {
	readconfig ( $CONFIG, \%banks );
}
# read the config file and get the bank parameter
if ( $args{'config'} ) {
	readconfig ( $args{'config'}, \%banks );
}
if ( keys %banks == 0 ) { die "FATAL: no bank found in config \"$CONFIG\"\n"; }



# go through each vault in each bank
foreach my $bank (keys %banks) {
	opendir LSV, $bank or die "FATAL: can't list vaults: $!\n";
	while ( defined ( my $vault = readdir LSV ) ) {
		if ( ! -d "$bank/$vault" or $vault =~ /^\./ ) { next; }
		# check each valut for days
		opendir LSD, "$bank/$vault"
			or die "FATAL: can't list vault \"$vault\": $!\n";
		my @days;
		while ( defined ( my $day = readdir LSD ) ) {
			if ( ! -d "$bank/$vault/$day" or $day !~ /^\d{8}$/ ) { next; }
			push @days, $day;
		}
		closedir LSD;
		my $previousday;
		foreach my $day (sort @days) {
			# skip if existing checksums
			my $process = 0;
			foreach (@CHECKS) {
				# skip if file exists or this typie is disabled
				if ( -f "$bank/$vault/$day/$_.bz2" ) {
					if ( $args{'debug'} ) { print "$bank/$vault/$day\n\texisting $_\n"; }
					next;
				}
				if ( $args{'no'.lc($_)} ) {
					if ( $args{'debug'} ) { print "$bank/$vault/$day\n\tdisabled (--no".lc($_).") $_\n"; }
					next;
				}
				# check this directory
				if ( $previousday ) {
					process_dir ( "$bank/$vault/$day",
							"$bank/$vault/$previousday" );
				} else {
					process_dir ( "$bank/$vault/$day" );
				}
			}
			# setup for next time round
			$previousday = $day;
		}
	}
	closedir LSV;
}









# generate checksums for specified directory (getting from previous if
# hard linked)
# takes 2 args: dir to check, previous generation dir
sub process_dir {
	my $dir = shift;
	my $previousdir = shift;
	# announce where we are working
	print "$dir\n";
	# evaluate inode cache to use previous inodes
	if ( ! $previousdir ) {
		undef %filestatsprev;
		undef %filesbyinodeprev;
		$inodespathprev = '';
	} elsif ( $previousdir eq $inodespathnew ) {
		# use new as previous
		print "\tUsing Previous Cache....\n";
		%filestatsprev = %filestatsnew;
		%filesbyinodeprev = %filesbyinodenew;
		$inodespathprev = $inodespathnew;
	} else {
		# we have no exisging inode data to go on
		undef %filestatsprev;
		undef %filesbyinodeprev;
		$inodespathprev = $previousdir;
		# read inodeinfo from indexes if available (might be the first backup so not available)
		if ( $previousdir and -f "$previousdir/index.gz" and -f "$previousdir/summary" ) {
			# read in previous index
			print "\tReading Previous index....\n";
			read_index ( \%filestatsprev, \%filesbyinodeprev, $previousdir );
		}
	}


	# we can't use any cached data for the directory we are working on (it's new!)
	undef %filestatsnew;
	$inodespathnew = $dir;
	# we can'd do this unless we have the basic files from an intact backup
	if ( ! $dir or ! -d $dir ) {
		die "$0: FATAL - Directory \"$dir\" to build checksums for doesn't exist\n";
	}
	if ( ! -f "$dir/index.gz" ) {
		die "$0: FATAL - Required files \"$dir/index.gz\" missing\n";
	}
	if ( ! -f "$dir/log.gz" ) {
		die "$0: FATAL - Required files \"$dir/log.gz\" missing\n";
	}
	# read in index
	print "\tReading New index....\n";
	read_index ( \%filestatsnew, \%filesbyinodenew, $dir );
	# parse log - this tells us files we definitely know have changed
	my %changedfiles;
	open my $dirvishlog, '-|', "$GZIP -d <\"$dir/log.gz\""
			or die "FATAL: can't process \"$GZIP -d <\"$dir/log.gz\"\": $!\n";
	print "\tReading log file....\n";
	my @parselines;
	my $logparserun = 0;
	while ( defined ( my $line = <$dirvishlog> ) ) {
		chomp $line;
		if ( $logparserun == 0 ) {
			unshift @parselines, $line;
			# look for starting condition
			if ( $parselines[0] =~ /^(sending|receiving) incremental file list$/
				and $parselines[1] eq ''
				and $parselines[2] =~ /^ACTION: .*rsync/
				and $parselines[3] eq '' ) {
				# found starting condition
				$logparserun = 1;
			}
		} else {
			# we are up and running
			if ( $line eq '' ) { last; }	# blank line at end of file list
			# we assume lines are either files or deletes
			if ( -e "$dir/tree/$line" ) {
				# good one - add to the changed list
				# if hard linked multiple files could change
				# both new and old inodes since we may be using ptrfs snapshots where the same inodes will get reused
				# so mark both as changed
				if ( exists ( $filestatsnew{"./$line"} ) ) {
					foreach (@{$filesbyinodenew{$filestatsnew{"./$line"}->{inode}}}) { $changedfiles{$_} = 1; }
				}
				if ( exists ( $filestatsprev{"./$line"} ) ) {
					foreach (@{$filesbyinodeprev{$filestatsprev{"./$line"}->{inode}}}) { $changedfiles{$_} = 1; }
				}
#print "change: ./$line\n";
			} elsif ( $line =~ /^deleting / ) {
				# assume this is a safe delete line
			} else {
				# probably something wrong
				die "FATAL: Changed file in \"$dir/log.gz\" missing: \"$dir/tree/$line\"\n";
			}
		}
	}
	close $dirvishlog;
	# process files based on each check
	foreach my $checksumfile (@CHECKS) {
		# skip if file exists or this type is disabled
		if ( -f "$dir/$checksumfile.bz2" or $args{'no'.lc($checksumfile)} ) { next; }
		# get checksums for previous files
		my %checksums;
		if ( $previousdir and -f "$previousdir/$checksumfile.bz2" ) {
			print "\tgetting checksums/inodes for previous $checksumfile....\n";
			open CHECKSUM, "$BZIP2 -d <\"$previousdir/$checksumfile.bz2\"|"
				or die "FATAL: can't process \"$BZIP2 -d <\"$previousdir/$checksumfile.bz2\"\": $!\n";
			while ( defined ( my $line = <CHECKSUM> ) ) {
				chomp $line;
				if ( $line =~ /^(\w+)\s+([^\s].+)$/ ) {
					my $inode;
					my ( $checksum, $path ) = ( $1, $2 );
					$path =~ s/^\//.\//;
					# use cached inodes as index
					$checksums{$filestatsprev{$path}->{inode}} = $checksum;
				}
			}
			close CHECKSUM;
		}
		# checksum remaining files
		print "\tgenerating $checksumfile....\n";
		my $pwd = getcwd;
		if ( ! chdir "$dir/tree" ) {
			print STDERR "\tWARNING: can't change directory to \"$dir/tree\": $!\n";
			return 1;
		}
		open CHECKSUM, '|-', "bzip2 >$dir/$checksumfile.bz2.TMP"
				or die "FATAL: can't write \"bzip2 >$dir/$checksumfile.bz2.TMP\": $!\n";
		my $filecount = 0;
		my $fileduplicate = 0;
		foreach my $line (sort keys %filestatsnew) {
			++$filecount;
			my $inode;
			$inode = $filestatsnew{$line}->{inode};
			if ( exists ( $checksums{$inode} ) and ! exists ( $changedfiles{$line} ) and exists ( $filestatsprev{$line} )
					and $filestatsnew{$line}->{inode} == $filestatsprev{$line}->{inode}
					and $filestatsnew{$line}->{user} eq $filestatsprev{$line}->{user}
					and $filestatsnew{$line}->{permissions} eq $filestatsprev{$line}->{permissions}
					and $filestatsnew{$line}->{group} eq $filestatsprev{$line}->{group}
					and $filestatsnew{$line}->{size} == $filestatsprev{$line}->{size}
					and $filestatsnew{$line}->{date} eq $filestatsprev{$line}->{date}
					and ( ! exists $filestatsnew{$line}->{mtime} or ! exists $filestatsprev{$line}->{mtime}
						or $filestatsnew{$line}->{mtime} == $filestatsprev{$line}->{mtime} ) ) {
# TODO yes - since inodes mya not change with btrfs snapshots, and generations may be skipped/deleted, logs & inodes don't have the whole story TODO
				print CHECKSUM "$checksums{$inode}  $line\n";
				++$fileduplicate;
			} else {
				# changed - need to checksum file
				my $sum;
				if ( $checksumfile eq 'SHA512SUMS' ) {
					my $sha = Digest::SHA->new ( 'sha512' );
					$sha->addfile ( $line );
					$sum = $sha->hexdigest;
				} elsif ( $checksumfile eq 'SHA1SUMS' ) {
					my $sha = Digest::SHA->new ( 'sha1' );
					$sha->addfile ( $line );
					$sum = $sha->hexdigest;
				} elsif ( $checksumfile eq 'MD5SUMS' ) {
					my $md5 = Digest::MD5->new;
					$md5->addfile ( $line );
					$sum = $md5->hexdigest;
				} else {
					die "$0: FATAL - unhandled checksum type \"$checksumfile\"\n";
				}
				if ( defined ( $sum ) ) {
					print CHECKSUM "$sum  $line\n";
				} else {
					print "ERROR:  \"$line\"\n";
				}
			}
		}
		close CHECKSUM;
		chdir $pwd;
		# rename to final file
		rename "$dir/$checksumfile.bz2.TMP", "$dir/$checksumfile.bz2";
		# stats
		if ( $filecount == 0 ) {
			print "\t\tWARNING:  No files found\n";
		} else {
			printf "\t\tunchanged %.1f %%\n", 100 * $fileduplicate / $filecount;
		}

	}
}












sub readconfig {
	my ( $config, $banks ) = @_;
	open my $conf, $config or die "FATAL: can't read \"$config\": $!\n";
	my $bankfound = 0;
	while ( defined ( my $line = <$conf> ) ) {
		chomp $line;
		if ( $line =~ s/^bank:\s*// ) {
			$bankfound = 1;
			chomp $line;
			if ( $line ne '' and -d $line ) { $$banks{$line} = 1; }
		} elsif ( $bankfound and $line =~ s/^\s+// ) {
			chomp $line;
			if ( $line ne '' and -d $line ) { $$banks{$line} = 1; }
		} else {
			$bankfound = 0;
		}
	}
	close $conf;
}




sub read_index {
	my ( $filestats, $filesbyinode, $dir, $statall ) = @_;
	# read in the summary
	my $tree;
	open SMRY, '<', "$dir/summary"
		or die "FATAL: can't read \"$dir/summary\": $!\n";
	while ( defined ( my $line = <SMRY> ) ) {
		chomp $line;
		if ( $line =~ /^tree:\s+([^\s].*)$/ ) {
			$tree = $1;
			last;
		}
	}
	close SMRY;
	if ( ! defined $tree ) {
		die "FATAL: can't find \$tree (required) in \"$dir/summary\"\n";
	}
	# read in the index
	open my $idx, '-|', "$GZIP -d <\"$dir/index.gz\""
		or die "FATAL: can't process \"$GZIP -d <\"$dir/index.gz\"\": $!\n";
	my $count = 0;
	while ( defined ( my $line = <$idx> ) ) {
		chomp $line;
		if ( $line =~ /^\s*(\d+)\s+\d+\s+(-[rwxsStT\-]+)\s+\d+\s+([^\s]+)\s+([^\s]+)\s+(\d+)\s+(\w+\s+\d+\s+[\d:]+)\s+([^\s].+)$/ ) {
			my ( $inode, $permissions, $user, $group, $size, $date, $file ) = ( $1, $2, $3, $4, $5, $6, $7 );
			$date =~ s/  +/ /g;
			if ( substr ( $file, 0, length $tree ) eq $tree ) {
				$file = substr $file, length $tree;
				$file =~ s/^\/*/.\//;
			} else {
				next;
			}
			$file =~ s/([^\\]) .*+$/$1/;	# clear everything after a real space
			$file =~ s/\\ / /g;		# convert spaces
			$file =~ s/\\"/"/g;		# convert quotes
			$file =~ s/\\\\/\\/g;		# convert backslashes
			$file =~ s/\\(\d{3})/pack('C',oct($1))/eg;
			# store vital statistics
			$$filestats{$file} = {
				permissions => $permissions,
				user => $user,
				group => $group,
				size => $size,
				date => $date,
			};
			# figure out valid inode
			++$count;
			if ( ! $statall ) {
				if ( $count % 2**int(log($count)) == 0 and (stat "$dir/tree/$file")[1] != $inode ) {
					# validation of this inode failed - can't depend on this data
					warn "\t!!! Validation of \"$dir/index.gz\" failed on \"$file\"\n";
					$count = -1;	# show we have a problem
					last;
				} else {
					# cache inodes by file to save time later
					$$filestats{$file}->{inode} = $inode;
					push @{$$filesbyinode{$inode}}, $file
				}
			} else {
				# must state each file for the inode
				my @stat = stat ( "$dir/tree/$file");
				if ( ! @stat ) {
					die "FATAL - can't stat \"$dir/tree/$file\"\n";
				}
				$$filestats{$file}->{inode} = $stat[1];
				$$filestats{$file}->{mtime} = $stat[9];
				push @{$$filesbyinode{$stat[1]}}, $file
			}
		}
	}
	close $idx;
	if ( $count < 0 ) {
		# we can't use existing inode list and have to read them all again (-1 indicates a problem / mismatch)
		# re-read in index stating all files
		undef %$filesbyinode;
		undef %$filestats;
		print "\t\tRe-reading index to check inodes....\n";
		read_index ( $filestats, $filesbyinode, $dir, 1 );
	}
}






