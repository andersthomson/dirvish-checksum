#!/usr/bin/perl
use strict;
use warnings;
# version:  20150101
# finds files in directory and MD5sums and SHA1sums them, being smart enough to
# check against previous backup for hard links
#
#
#
#
# Copyright (C) 2008-2015  Glen Pitt-Pladdy
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
#
# See https://www.pitt-pladdy.com/blog/_20120412-224240_0100_dirvish-checksum_available_again/


use Cwd;

# default config file
my $CONFIG = "/etc/dirvish/master.conf";

my $GZIP = "/bin/gzip";
my $BZIP2 = "/bin/bzip2";

my @CHECKS = (
	'MD5SUMS',
	'SHA1SUMS',
#	'SHA256SUMS',
	'SHA512SUMS',
);

# chaches
my $inodespathprev='';
my %inodesbyfileprev;
my %filesbyinodeprev;
my $inodespathnew='';
my %inodesbyfilenew;
my %filesbyinodenew;


# arguments accepted:
#	--nosha1sums	disables SHA1SUMS
#	--nomd5sums		disables MD5SUMS
#	--no......		disables ........
#	--config=<path>		alternate config file to use
#	--debug		prints extra info for debugging
#
# By default we generate SHA1 and MD5 checksums

# get command line args
my %args;
foreach my $arg (@ARGV) {
	if ( $arg =~ /^--([^\-=]+)$/ ) {
		# true value
		$args{$1} = 1;
	} elsif ( $arg =~ /^--([^\-=]+)=([^=]+)$/ ) {
		# specified value
		$args{$1} = $2;
	}
}
# check for "stupid users"
if (  $args{'nosha512ums'} and $args{'nosha1sums'} and $args{'nomd5sums'} ) {
	die "This is completely pointless - I give up!\n";
}
# check for unknown args
foreach my $arg (keys %args) {
	if ( $arg =~ /^no(.+)$/ ) {
		my $sum = uc $1;
		my $found = 0;
		foreach (@CHECKS) {
			if ( $sum eq $_ ) {
				$found = 1;
				last;
			}
		}
		if ( ! $found ) { usage (); }
	}
}
# check for usual calls for help
if ( $args{help} or $args{h} or $args{'?'} ) { usage (); }
sub usage {
	die "Usage: $0 [--no(checksumtype)] ...\n";
}

# get relevant algorithms in
foreach my $alg (@CHECKS) {
	if ( exists ( $args{'no'.lc($alg)} ) ) { next; }
	if ( $alg =~ /^SHA\d+SUMS$/ ) {
		use Digest::SHA;
	} elsif ( $alg eq 'MD5SUMS' ) {
		use Digest::MD5;
	}
}


# read the master config
my %banks;
if ( -f $CONFIG ) {
	readconfig ( $CONFIG, \%banks );
}
# read the config file and get the bank parameter
if ( $args{'config'} ) {
	readconfig ( $args{'config'}, \%banks );
}
if ( keys %banks == 0 ) { die "FATAL: no bank found in config \"$CONFIG\"\n"; }



# go through each vault in each bank
foreach my $bank (keys %banks) {
	opendir LSV, $bank or die "FATAL: can't list vaults: $!\n";
	while ( defined ( my $vault = readdir LSV ) ) {
		if ( ! -d "$bank/$vault" or $vault =~ /^\./ ) { next; }
		# check each valut for days
		opendir LSD, "$bank/$vault"
			or die "FATAL: can't list vault \"$vault\": $!\n";
		my @days;
		while ( defined ( my $day = readdir LSD ) ) {
			if ( ! -d "$bank/$vault/$day" or $day !~ /^\d{8}$/ ) { next; }
			push @days, $day;
		}
		closedir LSD;
		my $previousday;
		foreach my $day (sort @days) {
			# skip if existing checksums
			my $process = 0;
			foreach (@CHECKS) {
				# skip if file exists or this typie is disabled
				if ( -f "$bank/$vault/$day/$_.bz2" ) {
					if ( $args{'debug'} ) { print "$bank/$vault/$day\n\texisting $_\n"; }
					next;
				}
				if ( $args{'no'.lc($_)} ) {
					if ( $args{'debug'} ) { print "$bank/$vault/$day\n\tdisabled (--no".lc($_).") $_\n"; }
					next;
				}
				# check this directory
				if ( $previousday ) {
					process_dir ( "$bank/$vault/$day",
							"$bank/$vault/$previousday" );
				} else {
					process_dir ( "$bank/$vault/$day" );
				}
			}
			# setup for next time round
			$previousday = $day;
		}
	}
	closedir LSV;
}










sub readconfig {
	my ( $config, $banks ) = @_;
	open CONF, $config or die "FATAL: can't read \"$config\": $!\n";
	my $bankfound = 0;
	while ( defined ( my $line = <CONF> ) ) {
		chomp $line;
		if ( $line =~ s/^bank:\s*// ) {
			$bankfound = 1;
			chomp $line;
			if ( $line ne '' and -d $line ) { $$banks{$line} = 1; }
		} elsif ( $bankfound and $line =~ s/^\s+// ) {
			chomp $line;
			if ( $line ne '' and -d $line ) { $$banks{$line} = 1; }
		} else {
			$bankfound = 0;
		}
	}
	close CONF;
}




sub read_index {
	my ( $inodesbyfile, $filesbyinode, $dir, $statall ) = @_;
	# read in the summary
	my $tree;
	open SMRY, '<', "$dir/summary"
		or die "FATAL: can't read \"$dir/summary\": $!\n";
	while ( defined ( my $line = <SMRY> ) ) {
		chomp $line;
		if ( $line =~ /^tree:\s+([^\s].*)$/ ) {
			$tree = $1;
			last;
		}
	}
	close SMRY;
	if ( ! defined $tree ) {
		die "FATAL: can't find \$tree (required) in \"$dir/summary\"\n";
	}
	# read in the index
	open IDX, '-|', "$GZIP -d <\"$dir/index.gz\""
		or die "FATAL: can't process \"$GZIP -d <\"$dir/index.gz\"\": $!\n";
	my $count = 0;
	while ( defined ( my $line = <IDX> ) ) {
		chomp $line;
		if ( $line =~ /^\s*(\d+)\s+\d+\s+[\-][rwxsStT\-]+\s+\d+\s+[^\s]+\s+[^\s]+\s+\d+\s+\w+\s+\d+\s+(\d+:)?\d+\s+([^\s].+)$/ ) {
			my ( $inode, $file ) = ( $1, $3 );
# TODO include size & date? this would requrie storing size and date for comparison later TODO
			if ( substr ( $file, 0, length $tree ) eq $tree ) {
				$file = substr $file, length $tree;
				$file =~ s/^\/*/.\//;
			} else {
				next;
			}
			$file =~ s/([^\\]) .*+$/$1/;	# clear everything after a real space
			$file =~ s/\\ / /g;		# convert spaces
			$file =~ s/\\"/"/g;		# convert quotes
			$file =~ s/\\\\/\\/g;		# convert backslashes
			$file =~ s/\\(\d{3})/pack('C',oct($1))/eg;
#			if ( ! -e "$previousdir/tree/$file" ) { next; }
			++$count;
			if ( ! $statall ) {
				if ( $count % 2**int(log($count)) == 0 and (stat "$dir/tree/$file")[1] != $inode ) {
					# validation of this inode failed - can't depend on this data
					warn "\t!!! Validation of \"$dir/index.gz\" failed on \"$file\"\n";
					undef %$inodesbyfile;
					undef %$filesbyinode;
					$count = -1;	# show we have a problem
					last;
				} else {
					# cache inodes by file to save time later
					$$inodesbyfile{$file} = $inode;
					push @{$$filesbyinode{$inode}}, $file
				}
			} else {
				# must state each file for the inode
				my @stat = stat ( "$dir/tree/$file");
				if ( ! @stat ) {
					die "FATAL - can't stat \"$dir/tree/$file\"\n";
				}
				$$inodesbyfile{$file} = $stat[1];
				push @{$$filesbyinode{$stat[1]}}, $file
			}
		}
	}
	close IDX;
	if ( $count < 0 ) {
		# we can't use existing inode list and have to read them all again (-1 indicates a problem / mismatch)
		# re-read in index stating all files
		print "\t\tRe-reading index to check inodes....\n";
		read_index ( $inodesbyfile, $filesbyinode, $dir, 1 );
	}
}



# generate checksums for specified directory (getting from previous if
# hard linked)
# takes 2 args: dir to check, previous generation dir
sub process_dir {
	my $dir = shift;
	my $previousdir = shift;
	# announce where we are working
	print "$dir\n";
	# evaluate inode cache to use previous inodes
	if ( ! $previousdir ) {
		undef %inodesbyfileprev;
		undef %filesbyinodeprev;
		$inodespathprev = '';
	} elsif ( $previousdir eq $inodespathnew ) {
		# use new as previous
		print "\tUsing Previous Cache....\n";
		%inodesbyfileprev = %inodesbyfilenew;
		%filesbyinodeprev = %filesbyinodenew;
		$inodespathprev = $inodespathnew;
	} else {
		# we have no exisging inode data to go on
		undef %inodesbyfileprev;
		undef %filesbyinodeprev;
		$inodespathprev = $previousdir;
		# read inodeinfo from indexes if available (might be the first backup so not available)
		if ( $previousdir and -f "$previousdir/index.gz" and -f "$previousdir/summary" ) {
			# read in previous index
			print "\tReading Previous index....\n";
			read_index ( \%inodesbyfileprev, \%filesbyinodeprev, $previousdir );
		}
	}


	# we can't use any cached data for the directory we are working on (it's new!)
	undef %inodesbyfilenew;
	$inodespathnew = $dir;
	# we can'd do this unless we have the basic files from an intact backup
	if ( ! $dir or ! -d $dir ) {
		die "$0: FATAL - Directory \"$dir\" to build checksums for doesn't exist\n";
	}
	if ( ! -f "$dir/index.gz" ) {
		die "$0: FATAL - Required files \"$dir/index.gz\" missing\n";
	}
	if ( ! -f "$dir/log.gz" ) {
		die "$0: FATAL - Required files \"$dir/log.gz\" missing\n";
	}
	# read in index
	print "\tReading New index....\n";
	read_index ( \%inodesbyfilenew, \%filesbyinodenew, $dir );
	# parse log - this tells us files we definitely know have changed
	my %changedfiles;
	open my $dirvishlog, '-|', "$GZIP -d <\"$dir/log.gz\""
			or die "FATAL: can't process \"$GZIP -d <\"$dir/log.gz\"\": $!\n";
	print "\tReading log file....\n";
	my @parselines;
	my $logparserun = 0;
	while ( defined ( my $line = <$dirvishlog> ) ) {
		chomp $line;
		if ( $logparserun == 0 ) {
			unshift @parselines, $line;
			# look for starting condition
			if ( $parselines[0] =~ /^(sending|receiving) incremental file list$/
				and $parselines[1] eq ''
				and $parselines[2] =~ /^ACTION: .*rsync/
				and $parselines[3] eq '' ) {
				# found starting condition
				$logparserun = 1;
			}
		} else {
			# we are up and running
			if ( $line eq '' ) { last; }	# blank line at end of file list
			# we assume lines are either files or deletes
			if ( -e "$dir/tree/$line" ) {
				# good one - add to the changed list
# TODO but this will also impact other files hard linked to this one TODO
#				$changedfiles{"./$line"} = 1;
#if ( $line =~ /etc\/apache2\/(blocklist|local-addresses)\.conf/ ) {
#print "change: ./$line\n";
#print "\t".$inodesbyfilenew{"./$line"}."\n";
#foreach (@{$filesbyinodenew{$inodesbyfilenew{"./$line"}}}) {
#print "\t\t$_\n";
#}
#}
				# if hard linked multiple files could change
				# both new and old inodes since we may be using ptrfs snapshots where the same inodes will get reused
				# so mark both as changed
				if ( exists ( $inodesbyfilenew{"./$line"} ) ) {
					foreach (@{$filesbyinodenew{$inodesbyfilenew{"./$line"}}}) { $changedfiles{$_} = 1; }
				}
				if ( exists ( $inodesbyfileprev{"./$line"} ) ) {
					foreach (@{$filesbyinodeprev{$inodesbyfileprev{"./$line"}}}) { $changedfiles{$_} = 1; }
				}
#print "change: ./$line\n";
			} elsif ( $line =~ /^deleting / ) {
				# assume this is a safe delete line
			} else {
				# probably something wrong
				die "FATAL: Changed file in \"$dir/log.gz\" missing: \"$dir/tree/$line\"\n";
			}
		}
	}
	close $dirvishlog;
	# process files based on each check
	foreach my $checksumfile (@CHECKS) {
		# skip if file exists or this type is disabled
		if ( -f "$dir/$checksumfile.bz2" or $args{'no'.lc($checksumfile)} ) { next; }
		# get checksums for previous files
		my %checksums;
		if ( $previousdir and -f "$previousdir/$checksumfile.bz2" ) {
			print "\tgetting checksums/inodes for previous $checksumfile....\n";
			open CHECKSUM, "$BZIP2 -d <\"$previousdir/$checksumfile.bz2\"|"
				or die "FATAL: can't process \"$BZIP2 -d <\"$previousdir/$checksumfile.bz2\"\": $!\n";
			while ( defined ( my $line = <CHECKSUM> ) ) {
				chomp $line;
				if ( $line =~ /^(\w+)\s+([^\s].+)$/ ) {
					my $inode;
					my ( $checksum, $path ) = ( $1, $2 );
					$path =~ s/^\//.\//;
					# use cached inodes if available
					if ( exists $inodesbyfileprev{$path} ) {
						$inode = $inodesbyfileprev{$path};
					} else {
# TODO this should not occur - we should have got them either way by now TODO
die "$0: FATAL - this silly situation can't occur\n";
#						$inode = (stat "$previousdir/tree/$path")[1];
#						# cache inodes by file to save time later
#						$inodesbyfileprev{$path} = $inode;
					}
					if ( ! $inode ) {
						print STDERR "\tWARNING: no inode for \"$previousdir/tree/$path\"\n";
						next;
					}
					$checksums{$inode} = $checksum;
#if ( $line =~ /etc\/apache2\/blocklist\.conf/ ) { print "cache: $line\n\t$previousdir :: $inode :: $checksum\n"; }
#if ( $inode == 2044 ) { print "icache: $line\n\t$previousdir :: $checksum\n"; }
				}
			}
			close CHECKSUM;
		}
		# checksum remaining files
		print "\tgenerating $checksumfile....\n";
		my $pwd = getcwd;
		if ( ! chdir "$dir/tree" ) {
			print STDERR "\tWARNING: can't change directory to \"$dir/tree\": $!\n";
			return 1;
		}
		open CHECKSUM, '|-', "bzip2 >$dir/$checksumfile.bz2.TMP"
				or die "FATAL: can't write \"bzip2 >$dir/$checksumfile.bz2.TMP\": $!\n";
		my $filecount = 0;
		my $fileduplicate = 0;
		foreach my $line (sort keys %inodesbyfilenew) {
			++$filecount;
			my $inode;
			if ( exists $inodesbyfilenew{$line} ) {
				$inode = $inodesbyfilenew{$line};
			} else {
				$inode = (stat $line)[1];
				$inodesbyfilenew{$line} = $inode;
			}
			if ( $checksums{$inode} and ! $changedfiles{$line} ) {	# double check: inode and changed list
				# use the existing cached data
# TODO maybe we should check size and date for extra safety TODO
				print CHECKSUM "$checksums{$inode}  $line\n";
				++$fileduplicate;
#if ( $line =~ /etc\/apache2\/blocklist\.conf/ ) { print "existing: ./$line\n\t$inode :: $checksums{$inode}\n"; }
			} else {
#if ( $line =~ /etc\/apache2\/blocklist\.conf/ ) { print "new: ./$line\n"; }
				# changed - need to checksum file
				my $sum;
				if ( $checksumfile eq 'SHA512SUMS' ) {
					my $sha = Digest::SHA->new ( 'sha512' );
					$sha->addfile ( $line );
					$sum = $sha->hexdigest;
				} elsif ( $checksumfile eq 'SHA1SUMS' ) {
					my $sha = Digest::SHA->new ( 'sha1' );
					$sha->addfile ( $line );
					$sum = $sha->hexdigest;
				} elsif ( $checksumfile eq 'MD5SUMS' ) {
					my $md5 = Digest::MD5->new;
					$md5->addfile ( $line );
					$sum = $md5->hexdigest;
				} else {
					die "$0: FATAL - unhandled checksum type \"$checksumfile\"\n";
				}
				if ( defined ( $sum ) ) {
					print CHECKSUM "$sum  $line\n";
				} else {
					print "ERROR:  \"$line\"\n";
				}
			}
		}
		close CHECKSUM;
		chdir $pwd;
		# rename to final file
		rename "$dir/$checksumfile.bz2.TMP", "$dir/$checksumfile.bz2";
		# stats
		if ( $filecount == 0 ) {
			print "\t\tWARNING:  No files found\n";
		} else {
			printf "\t\thard linked %.1f %%\n", 100 * $fileduplicate / $filecount;
		}

	}
}



